#!/usr/bin/env python
""" commandline tool to grab article metadata from a given url """

import urllib2
import logging
from optparse import OptionParser
import re
import csv
import sys

from metareadability import metastuff

def main():
    parser = OptionParser(usage="%prog: [options]")
    parser.add_option('-v', '--verbose', action='store_true')
    parser.add_option('-d', '--debug', action='store_true')
    parser.add_option('-u', '--url', help="only test urls containing URL")
    (options, args) = parser.parse_args()

    log_level = logging.ERROR
    if options.debug:
        log_level = logging.DEBUG
    elif options.verbose:
        log_level = logging.INFO

    logging.basicConfig(level=log_level, format='%(message)s')

    for url in args:
        resp = urllib2.urlopen(url)
        html = resp.read()
        kwargs = {}
        content_type = resp.info().getheader('Content-Type','')
        m = re.compile(r';\s*charset\s*=\s*([^;]*)', re.I).search(content_type)
        if m:
            kwargs['encoding'] = m.group(1)
        headline,byline,pubdate = metastuff.extract(html, url, **kwargs)

        row = [url,headline,byline,unicode(pubdate.date())]
        row = [f.encode('utf-8') if f is not None else u'' for f in row]
        w = csv.writer(sys.stdout)
        w.writerow(row)

if __name__ == '__main__':
    main()

